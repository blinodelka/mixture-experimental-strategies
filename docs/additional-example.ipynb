{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import autora\n",
    "import numpy as np\n",
    "from typing import Iterable, Literal, Optional\n",
    "\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "\n",
    "from autora.experimentalist.sampler.falsification import falsification_sampler, falsification_score_sampler, falsification_score_sampler_from_predictions\n",
    "from autora.experimentalist.sampler.novelty import novelty_sampler, novelty_score_sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_distribution(p, temperature):\n",
    "        # temperature cannot be 0\n",
    "        #If the temperature is very low (close to 0), then the sampling will become almost deterministic, picking the event with the highest probability.\n",
    "        #If the temperature is very high, then the sampling will be closer to uniform, with all events having roughly equal probability.\n",
    "        \n",
    "        p = p / np.sum(p)  # Normalizing the initial distribution\n",
    "        p = np.log(p) / temperature  \n",
    "        p = np.exp(p)  \n",
    "        p = p / np.sum(p) # Normalizing the final distribution\n",
    "        return p\n",
    "\n",
    "\n",
    "    \n",
    "def mixture_sampler(condition_pool: np.ndarray, temperature: float, samplers: list, params: dict, num_samples: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        condition_pool: pool of experimental conditions to evaluate\n",
    "        temperature: how random is selection of conditions (cannot be 0; (0:1) - the choices are more deterministic than the choices made wrt\n",
    "        samplers: tuple containing sampler functions, their names, and weights \n",
    "        for sampler functions that return both positive and negative scores, user can provide a list with two weights: the first one will be applied to positive scores, the second one -- to the negative\n",
    "        params: nested dictionary. keys correspond to the sampler function names (same as provided in samplers),\n",
    "        values correspond to the dictionaries of function arguments (argument name: its value)\n",
    "        num_samples: number of experimental conditions to select\n",
    "        \n",
    "    Returns:\n",
    "        Sampled pool of experimental conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    rankings = []\n",
    "    scores = []\n",
    "    \n",
    "    ## getting rankings and weighted scores from each function\n",
    "    for (function, name, weight) in samplers:\n",
    "        sampler_params = params[name]\n",
    "        cur_ranking, cur_scores = function(condition_pool=condition_pool, **sampler_params)\n",
    "        cur_indices = np.argsort(cur_ranking, axis=None)\n",
    "        cur_ranking_sorted = cur_ranking[cur_indices]\n",
    "        rankings.append(cur_ranking_sorted) # for checking: all elements should be the same & same order\n",
    "        ## if function scores can be negative, then create a reversed dimension for them\n",
    "        if np.sum(cur_scores<0)>0:\n",
    "            \n",
    "            cur_scores_positive = np.copy(cur_scores)\n",
    "            cur_scores_positive[cur_scores<0]=0\n",
    "            cur_scores_negative = -np.copy(cur_scores)\n",
    "            cur_scores_negative[cur_scores>0]=0\n",
    "            \n",
    "            # aligning scores\n",
    "            cur_scores_positive_sorted = cur_scores_positive[cur_indices]\n",
    "            cur_scores_negative_sorted = cur_scores_negative[cur_indices]\n",
    "            \n",
    "            # if only one weight is provided, use it for both negative and positive dimensions\n",
    "            if isinstance(weight, int):\n",
    "                cur_scores_positive_weighted = cur_scores_positive_sorted * weight\n",
    "                cur_scores_negative_weighted = cur_scores_negative_sorted * weight\n",
    "            else:\n",
    "                cur_scores_positive_weighted = cur_scores_positive_sorted * weight[0] # positive dimension gets the first weight\n",
    "                cur_scores_negative_weighted = cur_scores_negative_sorted * weight[1] # negative dimension gets the second weight\n",
    "            \n",
    "            scores.append(cur_scores_positive_weighted)\n",
    "            scores.append(cur_scores_negative_weighted)\n",
    "            \n",
    "        else:\n",
    "            cur_scores_sorted = cur_scores[cur_indices]\n",
    "            if isinstance(weight, int):\n",
    "                cur_scores_weighted = cur_scores_sorted * weight\n",
    "            else: \n",
    "                cur_scores_weighted = cur_scores_sorted * weight[0]\n",
    "            scores.append(cur_scores_weighted)\n",
    "    \n",
    "    weighted_mixture_scores = np.sum(scores, axis = 0)\n",
    "    \n",
    "    # adjust mixture scores wrt temperature\n",
    "    weighted_mixture_scores_adjusted = adjust_distribution(weighted_mixture_scores, temperature)\n",
    "    \n",
    "    if num_samples is None:\n",
    "        num_samples = condition_pool.shape[0]\n",
    "    \n",
    "    conditions = np.random.choice(cur_ranking_sorted.T.squeeze(), num_samples,\n",
    "              p=weighted_mixture_scores_adjusted, replace = False)\n",
    "    \n",
    "    return conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use `novelty_score_sample` instead. `novelty_score_sampler` is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1460018   0.144641   -1.29064281]\n",
      "[ 1.1460018   0.144641   -1.29064281]\n",
      "[1.1460018 0.144641  0.       ]\n",
      "[0.         0.         1.29064281]\n",
      "[array([0.        , 0.0289282 , 0.22920036]), array([1.03251424, 0.        , 0.        ])]\n",
      "[array([[10],\n",
      "       [49],\n",
      "       [59]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([49, 59, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_sampler(condition_pool = np.array([10,49,59]),temperature = 20, \n",
    "    samplers = [[novelty_score_sampler, \"novelty\", [0.2,0.8]]], params = {\"novelty\": {\"reference_conditions\": np.array([12,25,30])}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_distribution(p, temperature):\n",
    "        # temperature cannot be 0\n",
    "        #If the temperature is very low (close to 0), then the sampling will become almost deterministic, picking the event with the highest probability.\n",
    "        #If the temperature is very high, then the sampling will be closer to uniform, with all events having roughly equal probability.\n",
    "        \n",
    "        p = p / np.sum(p)  # Normalizing the initial distribution\n",
    "        p = np.log(p) / temperature  \n",
    "        p = np.exp(p)  \n",
    "        p = p / np.sum(p) # Normalizing the final distribution\n",
    "        return p\n",
    "\n",
    "\n",
    "    \n",
    "def mixture_sampler(\n",
    "    condition_pool: np.ndarray, weights: np.ndarray, temperature: int, \n",
    "    X_ref: np.ndarray, \n",
    "    X_train: np.ndarray,\n",
    "    Y_train: np.ndarray, Y_predicted, num_samples: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Add a description of the sampler here.\n",
    "\n",
    "    Args:\n",
    "        condition_pool: pool of experimental conditions to evaluate\n",
    "        num_samples: number of experimental conditions to select\n",
    "        weights: array containing 4 weights -- importance of the falsification, confirmation, novelty, and familiarity (ideally, each pair of opposites? sums up to 1 or all? sum up to 1)\n",
    "        temperature: how random is selection of conditions (cannot be 0; (0:1) - the choices are more deterministic than the choices made wrt\n",
    "        the mixture scores; 1 - choices are made wrt to the mixture scores; (1, inf) - the choices are more random)\n",
    "        X_ref, X_train, Y_train, Y_predicted: parameters required for falsification and novelty samplers\n",
    "    \n",
    "    Returns:\n",
    "        Sampled pool of experimental conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    falsification_ranking, falsification_scores = get_scored_samples_from_model_prediction(condition_pool, \n",
    "                                                                                           Y_predicted, X_train,\n",
    "                                                                                           Y_train, n=condition_pool.shape[0])\n",
    "    \n",
    "    # getting rid of negative scores by introducing confirmation scores \n",
    "    confirmation_scores = -falsification_scores\n",
    "    confirmation_scores[falsification_scores>0]=0\n",
    "    falsification_scores[falsification_scores<0]=0\n",
    "    \n",
    "    # getting rid of negative scores by introducing familiarity scores \n",
    "    novelty_ranking, novelty_scores = novelty_score_sample(condition_pool, X_ref, n=condition_pool.shape[0])\n",
    "    \n",
    "    familiarity_scores = -novelty_scores\n",
    "    familiarity_scores[novelty_scores>0]=0\n",
    "    novelty_scores[novelty_scores<0]=0\n",
    "    \n",
    "    # aligning the arrays based on the observations (condition pools)\n",
    "    novelty_indices = np.argsort(novelty_ranking, axis=None)\n",
    "    ranking_sorted = novelty_ranking[novelty_indices]\n",
    "    novelty_scores_sorted = novelty_scores[novelty_indices]\n",
    "    familiarity_scores_sorted = familiarity_scores[novelty_indices]\n",
    "\n",
    "    falsification_indices = np.argsort(falsification_ranking, axis=None)\n",
    "    falsification_scores_sorted = falsification_scores[falsification_indices]    \n",
    "    confirmation_scores_sorted = confirmation_scores[falsification_indices] \n",
    "    \n",
    "    weighted_mixture_scores = falsification_scores_sorted * weights[0] + confirmation_scores_sorted * weights[1] + novelty_scores_sorted * weights[2] + familiarity_scores_sorted * weights[3] \n",
    "    # each score is weighted by the relative importance of these different axes\n",
    "    \n",
    "    \n",
    "    # adjust mixture scores wrt temperature\n",
    "    weighted_mixture_scores_adjusted = adjust_distribution(weighted_mixture_scores, temperature)\n",
    "    \n",
    "    if num_samples is None:\n",
    "        num_samples = condition_pool.shape[0]\n",
    "    \n",
    "    conditions = np.random.choice(ranking_sorted.T.squeeze(), num_samples,\n",
    "              p=weighted_mixture_scores_adjusted, replace = False)\n",
    "    \n",
    "    return conditions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MixtureExperimentalist:\n",
    "    def __init__(self, weights: np.ndarray, temperature: int, \n",
    "    X_ref: np.ndarray, \n",
    "    X_train: np.ndarray,\n",
    "    Y_train: np.ndarray, Y_predicted, num_samples: Optional[int] = None):\n",
    "        self.weights = weights\n",
    "        self.temperature = temperature\n",
    "        self.X_ref = X_ref\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_predicted = Y_predicted\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __call__(self, condition_pool: np.ndarray, **kwargs):\n",
    "        params = dict(weights = self.weights, temperature = self.temperature, X_ref = self.X_ref,\n",
    "                     X_train = self.X_train, Y_train = self.Y_train, Y_predicted = self.Y_predicted,\n",
    "                     num_samples = self.num_samples)\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        samples = mixture_sampler(condition_pool, **params)\n",
    "        return samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'condition_pool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m experimentalist \u001b[38;5;241m=\u001b[39m \u001b[43mMixtureExperimentalist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition_pool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m49\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnovelty_score_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnovelty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnovelty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_ref\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'condition_pool'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "experimentalist = MixtureExperimentalist(condition_pool = np.array([10,49,59]),temperature = 20, \n",
    "    samplers = ([novelty_score_sampler, \"novelty\", [0.2,0.8]]), params = {\"novelty\": {\"X_ref\": np.array([10,25,30])}})\n",
    "    #X_ref = np.array([10,25,30]),\n",
    "    #X_train = np.array([2,5,6]),\n",
    "    #Y_train = np.array([20,25,26]), Y_predicted = np.array([21,22,23]), num_samples = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mixture_sampler() got an unexpected keyword argument 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexperimentalist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition_pool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mMixtureExperimentalist.__call__\u001b[0;34m(self, condition_pool, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature, X_ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_ref,\n\u001b[1;32m     16\u001b[0m              X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, Y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_train, Y_predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_predicted,\n\u001b[1;32m     17\u001b[0m              num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples)\n\u001b[1;32m     18\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m---> 20\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mmixture_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "\u001b[0;31mTypeError\u001b[0m: mixture_sampler() got an unexpected keyword argument 'weights'"
     ]
    }
   ],
   "source": [
    "experimentalist(condition_pool = np.array([1,2,3]), num_samples = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_sampler(\n",
    "    np.array([1,2,3]), np.array([0.2,0.3,0.3,0.7]), 20, \n",
    "    np.array([10,25,30]), \n",
    "    np.array([2,5,6]),\n",
    "    np.array([20,25,26]), np.array([21,22,23]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use `novelty_score_sample` instead. `novelty_score_sampler` is deprecated.\n",
      "/var/folders/xk/2c6fkk5d1vd7qqn6thv9bd_40000gq/T/ipykernel_33762/3667485654.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  p = np.log(p) / temperature\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fewer non-zero entries in p than size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmixture_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition_pool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m49\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnovelty_score_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnovelty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnovelty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreference_conditions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 79\u001b[0m, in \u001b[0;36mmixture_sampler\u001b[0;34m(condition_pool, temperature, samplers, params, num_samples)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m condition_pool\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m conditions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_ranking_sorted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m          \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_mixture_scores_adjusted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conditions\n",
      "File \u001b[0;32mmtrand.pyx:991\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Fewer non-zero entries in p than size"
     ]
    }
   ],
   "source": [
    "mixture_sampler(condition_pool = np.array([10,49,59]),temperature = 20, \n",
    "    samplers = [[novelty_score_sampler, \"novelty\", [0.2,0.8]]], params = {\"novelty\": {\"reference_conditions\": np.array([12,25,30])}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
